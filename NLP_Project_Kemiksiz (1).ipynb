{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nfrom pyspark.sql import Row\nfrom pyspark.sql.functions import col,pandas_udf, PandasUDFType,count\nfrom pyspark import SparkContext,SparkConf\nfrom pyspark.sql import SparkSession\nimport nltk\n\nfrom pyspark.ml.feature import HashingTF, IDF, RegexTokenizer,StopWordsRemover,VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom mleap.sklearn.preprocessing.data import FeatureExtractor, LabelEncoder, ReshapeArrayToN1\nfrom pyspark.ml.evaluation import RegressionEvaluator,MulticlassClassificationEvaluator,BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.sql.functions import *"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["df = spark.table(some_file)\ndf.cache()\n\ncleardf=df.na.drop()\ndisplay(cleardf.groupby('label').count())"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["train_df, test_df = alldf.randomSplit([0.65, 0.35], seed = 2018)\n\nprint(\"Training Dataset Count: \" + str(train_df.count()))\nprint(\"Test Dataset Count: \" + str(test_df.count()))\n\ntrain_df.cache()\ntest_df.cache()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["stopWordstr = StopWordsRemover.loadDefaultStopWords(\"turkish\")\n\nregexTokenizer = RegexTokenizer(inputCol=\"Text\", outputCol=\"words\", pattern=' |,|;|-|_|\\*|\\t|\\!|\\.|\\*|\\:|\\(|\\|\\\"|\\&|\\$|\\|\\#|\\}|\\]|\\[|\\)|\\{|\\/|\\'|<|>',toLowercase=True)\n\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\",stopWords =stopWordstr)\n\nhashtf = HashingTF(inputCol=\"filtered\", outputCol='tf')\n\nidf = IDF(inputCol='tf', outputCol=\"tffeatures\")\n\nva = VectorAssembler(inputCols=[\"tf\", \"tffeatures\"], outputCol=\"features\") \n\nlr = LogisticRegression()\n\npipelinelr = Pipeline(stages=[stopWordstr,regexTokenizer,remover,hashtf, idf,va,lr])"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["paramGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.006])\n             .addGrid(idf.minDocFreq,[2])\n             .addGrid(hashtf.numFeatures, [2**18])\n             .addGrid(hashtf.binary, [True])\n             .addGrid(lr.fitIntercept, [True])\n             .addGrid(lr.standardization, [True])\n             .addGrid(lr.elasticNetParam, [0.1])\n             .addGrid(lr.aggregationDepth, [2])\n             .addGrid(lr.maxIter,[1])\n             .addGrid(lr.tol,[1e-06])\n             .build()  )\n\ncvlr = CrossValidator(estimator=pipelinelr, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid)\n\ncvModel = cvlr.fit(train_df)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["predictions = modellr.transform(test_df)\n \n\npredictions = predictions.select(col(\"label\").cast(\"Float\"),col(\"prediction\"))\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Error = %g\" % (1.0 - accuracy))\n\n \nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Accuracy = %g\" % accuracy)\n \nevaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\nf1 = evaluatorf1.evaluate(predictions)\nprint(\"f1 = %g\" % f1)\n \nevaluatorwp = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\nwp = evaluatorwp.evaluate(predictions)\nprint(\"weightedPrecision = %g\" % wp)\n \nevaluatorwr = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\nwr = evaluatorwr.evaluate(predictions)\nprint(\"weightedRecall = %g\" % wr)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["%sh \nrm -rf /tmp/model_export\nmkdir /tmp/model_export"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["import sys\nsys.path.append('/opt/libs/mleap/python')\n\nimport mleap.pyspark\nfrom mleap.pyspark.spark_support import SimpleSparkSerializer\n\n        \nmodellr.serializeToBundle(\"jar:file:/tmp/model_export/LR_model.zip\",predictionslr)"],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"NLP_Project_Kemiksiz","notebookId":2877063710763561},"nbformat":4,"nbformat_minor":0}
