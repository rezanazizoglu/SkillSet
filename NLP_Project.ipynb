{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nfrom pyspark.sql import Row\nfrom pyspark.sql.functions import col,pandas_udf, PandasUDFType,count\nfrom pyspark import SparkContext,SparkConf\nfrom pyspark.sql import SparkSession\nimport nltk\n\n#Install Tagged file from databricks table\nmultiban = spark.table(\"allban\")\nmultiban.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">1</span><span class=\"ansired\">]: </span>DataFrame[label: int, Text: string]\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["multiban=multiban.na.drop()\ndisplay(multiban.groupby('label').count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>label</th><th>count</th></tr></thead><tbody><tr><td>1</td><td>6367</td></tr><tr><td>0</td><td>29281</td></tr></tbody></table></div>"]}}],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql.types import IntegerType\nmultiban = multiban.withColumn(\"label\", multiban[\"label\"].cast(IntegerType()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["train_df, test_df = multiban.randomSplit([0.65, 0.35], seed = 2018)\n\nprint(\"Training Dataset Count: \" + str(train_df.count()))\nprint(\"Test Dataset Count: \" + str(test_df.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 23092\nTest Dataset Count: 12556\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["train_df.cache()\ntest_df.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>DataFrame[label: int, Text: string]\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, RegexTokenizer,StopWordsRemover,VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression,NaiveBayes,LinearSVC,GBTClassifier\nfrom mleap.sklearn.preprocessing.data import FeatureExtractor, LabelEncoder, ReshapeArrayToN1\nfrom pyspark.ml.evaluation import RegressionEvaluator,MulticlassClassificationEvaluator,BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit,CrossValidator\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.sql.functions import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["print(StopWordsRemover.loadDefaultStopWords(\"turkish\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&apos;acaba&apos;, &apos;ama&apos;, &apos;aslında&apos;, &apos;az&apos;, &apos;bazı&apos;, &apos;belki&apos;, &apos;biri&apos;, &apos;birkaç&apos;, &apos;birşey&apos;, &apos;biz&apos;, &apos;bu&apos;, &apos;çok&apos;, &apos;çünkü&apos;, &apos;da&apos;, &apos;daha&apos;, &apos;de&apos;, &apos;defa&apos;, &apos;diye&apos;, &apos;eğer&apos;, &apos;en&apos;, &apos;gibi&apos;, &apos;hem&apos;, &apos;hep&apos;, &apos;hepsi&apos;, &apos;her&apos;, &apos;hiç&apos;, &apos;için&apos;, &apos;ile&apos;, &apos;ise&apos;, &apos;kez&apos;, &apos;ki&apos;, &apos;kim&apos;, &apos;mı&apos;, &apos;mu&apos;, &apos;mü&apos;, &apos;nasıl&apos;, &apos;ne&apos;, &apos;neden&apos;, &apos;nerde&apos;, &apos;nerede&apos;, &apos;nereye&apos;, &apos;niçin&apos;, &apos;niye&apos;, &apos;o&apos;, &apos;sanki&apos;, &apos;şey&apos;, &apos;siz&apos;, &apos;şu&apos;, &apos;tüm&apos;, &apos;ve&apos;, &apos;veya&apos;, &apos;ya&apos;, &apos;yani&apos;]\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["stopWordstr = ['❤️', '◻', '😑', '🙏🏻', '🌸', '🙌🏻',  '😇',  '😊', '😢', '⭐️', '🌼', '🙈', '🍀', '💗', '💕', '😊', '🌺', '😅', '💵', '🙈', '🙏🙏🙏', '🙏🙏', '✔️', '😌🙏🏻', '😍', '👍', '👍👍', '👍👍👍', ':)', '👏🏼', '👏🏼👏🏼', '👏🏼👏🏼👏🏼', '🤔', '☺️', '😑😑', '😑', ':(', '😊', '👌👌', '👌', '💃🏻', '✌🏻', ':))', ':)))', '🎃','😉','😄','🤗']\n\nregexTokenizer = RegexTokenizer(inputCol=\"Text\", outputCol=\"words\", pattern=' |,|;|-|_|\\*|\\t|\\!|\\.|\\*|\\:|\\(|\\|\\\"|\\&|\\$|\\|\\#|\\}|\\]|\\[|\\)|\\{|\\/|\\'|<|>',toLowercase=True)\n\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\",stopWords =stopWordstr)\n\nhashtf = HashingTF(inputCol=\"filtered\", outputCol='tf')\n\nidf = IDF(inputCol='tf', outputCol=\"tffeatures\")\n\nva = VectorAssembler(inputCols=[\"tf\", \"tffeatures\"], outputCol=\"features\") \n\nlr = LogisticRegression()\nnv= NaiveBayes()\nlsvc=LinearSVC()\ngbt = GBTClassifier()\n\npipelinelr = Pipeline(stages=[regexTokenizer,remover,hashtf, idf,va,lr])\npipelinenv = Pipeline(stages=[regexTokenizer,remover,hashtf, idf, nv])\npipelinelsvc = Pipeline(stages=[regexTokenizer,remover,hashtf, idf, lsvc])\npipelinegbt = Pipeline(stages=[regexTokenizer,remover,hashtf, idf, gbt])\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.0001,0.006,0.003,0.01,0.03])\n             .addGrid(idf.minDocFreq,[2,3,4])\n             .addGrid(hashtf.numFeatures, [2**3,2**18])\n             .addGrid(hashtf.binary, [True,False])\n             .addGrid(lr.fitIntercept, [True,False])\n             .addGrid(lr.standardization, [True,False])\n             .addGrid(lr.elasticNetParam, [0.01,0.05,0.1])\n             .addGrid(lr.aggregationDepth, [2,3])\n             .addGrid(lr.maxIter,[5,1000])\n             .addGrid(lr.family,['binomial'])\n             .addGrid(lr.tol,[1e-06,1e-01])\n             .build()  )\n\ncvlr = CrossValidator(estimator=pipelinelr, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid)\n\ncvModel = cvlr.fit(train_df)\nmodellr = cvModel.bestModel"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["modellr.stages[4].extractParamMap()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["paramGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.006])\n             #.addGrid(idf.minDocFreq,[2])\n             .addGrid(hashtf.numFeatures, [2**18])\n             #.addGrid(hashtf.binary, [True])\n             #.addGrid(lr.fitIntercept, [True])\n             #.addGrid(lr.standardization, [True])\n             #.addGrid(lr.elasticNetParam, [0.1])\n             #.addGrid(lr.aggregationDepth, [2])\n             #.addGrid(lr.maxIter,[1])\n             #.addGrid(lr.tol,[1e-06])\n             .build()  )\n\ncvlr = CrossValidator(estimator=pipelinelr, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid)\n\ncvModel = cvlr.fit(train_df)\nmodellr = cvModel.bestModel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["predictions = modellr.transform(test_df)\n \n\npredictions = predictions.select(col(\"label\").cast(\"Float\"),col(\"prediction\"))\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Error = %g\" % (1.0 - accuracy))\n\n \nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Accuracy = %g\" % accuracy)\n \nevaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\nf1 = evaluatorf1.evaluate(predictions)\nprint(\"f1 = %g\" % f1)\n \nevaluatorwp = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\nwp = evaluatorwp.evaluate(predictions)\nprint(\"weightedPrecision = %g\" % wp)\n \nevaluatorwr = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\nwr = evaluatorwr.evaluate(predictions)\nprint(\"weightedRecall = %g\" % wr)\n\nevaluatorpr = BinaryClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"areaUnderPR\")\npr = evaluatorpr.evaluate(predictions)\nprint(\"areaUnderPR = %g\" % pr)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-837974679672910&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     24</span> print<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;weightedRecall = %g&quot;</span> <span class=\"ansiyellow\">%</span> wr<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     25</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 26</span><span class=\"ansiyellow\"> </span>evaluatorpr <span class=\"ansiyellow\">=</span> BinaryClassificationEvaluator<span class=\"ansiyellow\">(</span>labelCol<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">&quot;label&quot;</span><span class=\"ansiyellow\">,</span> predictionCol<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">&quot;prediction&quot;</span><span class=\"ansiyellow\">,</span> metricName<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">&quot;areaUnderPR&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     27</span> pr <span class=\"ansiyellow\">=</span> evaluatorpr<span class=\"ansiyellow\">.</span>evaluate<span class=\"ansiyellow\">(</span>predictions<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     28</span> print<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;areaUnderPR = %g&quot;</span> <span class=\"ansiyellow\">%</span> pr<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/__init__.py</span> in <span class=\"ansicyan\">wrapper</span><span class=\"ansiblue\">(self, *args, **kwargs)</span>\n<span class=\"ansigreen\">    103</span>             <span class=\"ansigreen\">raise</span> TypeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Method %s forces keyword arguments.&quot;</span> <span class=\"ansiyellow\">%</span> func<span class=\"ansiyellow\">.</span>__name__<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    104</span>         self<span class=\"ansiyellow\">.</span>_input_kwargs <span class=\"ansiyellow\">=</span> kwargs<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 105</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> func<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kwargs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    106</span>     <span class=\"ansigreen\">return</span> wrapper<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    107</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TypeError</span>: __init__() got an unexpected keyword argument &apos;predictionCol&apos;</div>"]}}],"execution_count":12},{"cell_type":"code","source":["evaluatorpr = BinaryClassificationEvaluator(labelCol=\"label\", predictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\npr = evaluatorpr.evaluate(predictions)\nprint(\"areaUnderPR = %g\" % pr)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-348649863844189&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>evaluatorpr <span class=\"ansiyellow\">=</span> BinaryClassificationEvaluator<span class=\"ansiyellow\">(</span>labelCol<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">&quot;label&quot;</span><span class=\"ansiyellow\">,</span> predictionCol<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">&quot;rawPrediction&quot;</span><span class=\"ansiyellow\">,</span> metricName<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">&quot;areaUnderPR&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> pr <span class=\"ansiyellow\">=</span> evaluatorpr<span class=\"ansiyellow\">.</span>evaluate<span class=\"ansiyellow\">(</span>predictions<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> print<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;areaUnderPR = %g&quot;</span> <span class=\"ansiyellow\">%</span> pr<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/__init__.py</span> in <span class=\"ansicyan\">wrapper</span><span class=\"ansiblue\">(self, *args, **kwargs)</span>\n<span class=\"ansigreen\">    103</span>             <span class=\"ansigreen\">raise</span> TypeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Method %s forces keyword arguments.&quot;</span> <span class=\"ansiyellow\">%</span> func<span class=\"ansiyellow\">.</span>__name__<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    104</span>         self<span class=\"ansiyellow\">.</span>_input_kwargs <span class=\"ansiyellow\">=</span> kwargs<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 105</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> func<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kwargs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    106</span>     <span class=\"ansigreen\">return</span> wrapper<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    107</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TypeError</span>: __init__() got an unexpected keyword argument &apos;predictionCol&apos;</div>"]}}],"execution_count":13},{"cell_type":"code","source":["paramGrid = (ParamGridBuilder()\n             .addGrid(hashtf.numFeatures, [2**16])\n             #.addGrid(lsvc.regParam, [0.1])\n             .build()  )\n\ncvlsvc = CrossValidator(estimator=pipelinelsvc, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid)\n\ncvModel = cvlsvc.fit(train_df)\nmodellsvc = cvModel.bestModel\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["modellsvc.stages[5].extractParamMap()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">42</span><span class=\"ansired\">]: </span>\n{Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;fitIntercept&apos;, doc=&apos;whether to fit an intercept term&apos;): True,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;predictionCol&apos;, doc=&apos;prediction column name&apos;): &apos;prediction&apos;,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;tol&apos;, doc=&apos;the convergence tolerance for iterative algorithms (&gt;= 0)&apos;): 1e-06,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;threshold&apos;, doc=&apos;threshold in binary classification prediction applied to rawPrediction&apos;): 0.0,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;standardization&apos;, doc=&apos;whether to standardize the training features before fitting the model&apos;): True,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;regParam&apos;, doc=&apos;regularization parameter (&gt;= 0)&apos;): 0.1,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;maxIter&apos;, doc=&apos;maximum number of iterations (&gt;= 0)&apos;): 100,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;aggregationDepth&apos;, doc=&apos;suggested depth for treeAggregate (&gt;= 2)&apos;): 2,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;labelCol&apos;, doc=&apos;label column name&apos;): &apos;label&apos;,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;featuresCol&apos;, doc=&apos;features column name&apos;): &apos;features&apos;,\n Param(parent=&apos;LinearSVC_46a5ae11c6867ccf8ef7&apos;, name=&apos;rawPredictionCol&apos;, doc=&apos;raw prediction (a.k.a. confidence) column name&apos;): &apos;rawPrediction&apos;}\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["\nparamGrid = (ParamGridBuilder()\n             .addGrid(hashtf.numFeatures, [2**16])\n             .addGrid(nv.smoothing, [0.065])\n             .build()  )\n\ncvnv = CrossValidator(estimator=pipelinenv, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid)\n\ncvModel = cvnv.fit(train_df)\nmodelnv = cvModel.bestModel\n\n\n\npredictions = modelnv.transform(test_df)\n \n\npredictions = predictions.select(col(\"label\").cast(\"Float\"),col(\"prediction\"))\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Error = %g\" % (1.0 - accuracy))\n\n \nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Accuracy = %g\" % accuracy)\n \nevaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\nf1 = evaluatorf1.evaluate(predictions)\nprint(\"f1 = %g\" % f1)\n \nevaluatorwp = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\nwp = evaluatorwp.evaluate(predictions)\nprint(\"weightedPrecision = %g\" % wp)\n \nevaluatorwr = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\nwr = evaluatorwr.evaluate(predictions)\nprint(\"weightedRecall = %g\" % wr)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["predictions = modellsvc.transform(test_df)\n \n\npredictions = predictions.select(col(\"label\").cast(\"Float\"),col(\"prediction\"))\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Error = %g\" % (1.0 - accuracy))\n\n \nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Accuracy = %g\" % accuracy)\n \nevaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\nf1 = evaluatorf1.evaluate(predictions)\nprint(\"f1 = %g\" % f1)\n \nevaluatorwp = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\nwp = evaluatorwp.evaluate(predictions)\nprint(\"weightedPrecision = %g\" % wp)\n \nevaluatorwr = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\nwr = evaluatorwr.evaluate(predictions)\nprint(\"weightedRecall = %g\" % wr)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Error = 0.0833864\nAccuracy = 0.916614\nf1 = 0.914963\nweightedPrecision = 0.914109\nweightedRecall = 0.916614\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["paramGrid = (ParamGridBuilder()\n             .addGrid(hashtf.numFeatures, [2**12])\n             .build()  )\n\ncvgbt = CrossValidator(estimator=pipelinegbt, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid)\n\ncvModel = cvgbt.fit(train_df)\nmodelgbt = cvModel.bestModel\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["predictions = modelgbt.transform(test_df)\n \n\npredictions = predictions.select(col(\"label\").cast(\"Float\"),col(\"prediction\"))\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Error = %g\" % (1.0 - accuracy))\n\n \nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Accuracy = %g\" % accuracy)\n \nevaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\nf1 = evaluatorf1.evaluate(predictions)\nprint(\"f1 = %g\" % f1)\n \nevaluatorwp = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\nwp = evaluatorwp.evaluate(predictions)\nprint(\"weightedPrecision = %g\" % wp)\n \nevaluatorwr = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\nwr = evaluatorwr.evaluate(predictions)\nprint(\"weightedRecall = %g\" % wr)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Error = 0.128616\nAccuracy = 0.871384\nf1 = 0.845814\nweightedPrecision = 0.873945\nweightedRecall = 0.871384\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["display(predictionslr,5)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["%sh \nrm -rf /tmp/model_export\nmkdir /tmp/model_export"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["import sys\nsys.path.append('/opt/libs/mleap/python')\n\nimport mleap.pyspark\nfrom mleap.pyspark.spark_support import SimpleSparkSerializer\n\n        \nmodellr.serializeToBundle(\"jar:file:/tmp/model_export/LR_model_vsX-json.zip\",predictionslr)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["predictionAndLabels = test_df.map(lambda lp: (float(modellr.predict(lp.features)), lp.label))\n\n# Instantiate metrics object\nmetrics = BinaryClassificationMetrics(predictionAndLabels)\n\n# Area under precision-recall curve\nprint(\"Area under PR = %s\" % metrics.areaUnderPR)\n\n# Area under ROC curve\nprint(\"Area under ROC = %s\" % metrics.areaUnderROC)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-2686753707922364&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>predictionAndLabels <span class=\"ansiyellow\">=</span> test_df<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> lp<span class=\"ansiyellow\">:</span> <span class=\"ansiyellow\">(</span>float<span class=\"ansiyellow\">(</span>modellr<span class=\"ansiyellow\">.</span>predict<span class=\"ansiyellow\">(</span>lp<span class=\"ansiyellow\">.</span>features<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> lp<span class=\"ansiyellow\">.</span>label<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansired\"># Instantiate metrics object</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> metrics <span class=\"ansiyellow\">=</span> BinaryClassificationMetrics<span class=\"ansiyellow\">(</span>predictionAndLabels<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">__getattr__</span><span class=\"ansiblue\">(self, name)</span>\n<span class=\"ansigreen\">   1243</span>         <span class=\"ansigreen\">if</span> name <span class=\"ansigreen\">not</span> <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>columns<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1244</span>             raise AttributeError(\n<span class=\"ansigreen\">-&gt; 1245</span><span class=\"ansiyellow\">                 &quot;&apos;%s&apos; object has no attribute &apos;%s&apos;&quot; % (self.__class__.__name__, name))\n</span><span class=\"ansigreen\">   1246</span>         jc <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>apply<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1247</span>         <span class=\"ansigreen\">return</span> Column<span class=\"ansiyellow\">(</span>jc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;DataFrame&apos; object has no attribute &apos;map&apos;</div>"]}}],"execution_count":23}],"metadata":{"name":"NLP_Project","notebookId":843302227551354},"nbformat":4,"nbformat_minor":0}
